---
title: "Practical Machine Learning Course Project"
author: "David H"
date: "22/12/2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Prediction of Weight Lifting Exercise Quality
#### Background
Over the last few years, there has been a massive increase in the no of gym users using wearable devices such as Fitbit, Jawbone Up and Nike FuelBand. Typically, these are used to quantify the amount of a particular activity done. Rarely, has analysis been done into the quality of the exercise. Using data from accelerometers on the belt, forearm, arm and dumbell, 6 different participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The source of this data is taken from:  http://groupware.les.inf.puc-rio.br/har .

#### Aim
The aim of this project is to build a model that uses the measurements from the accelerometers and classify which of the 5 different ways weight lifting was performed. For reference, outcome class A represents the "correct"" way where B,C,D and E classes correspond to 4 common mistakes. 

#### Data
The training data on which the classification model was built is stored here:  
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The validation data contains 20 validation cases without outcome is stored here:  
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

Both of these csv files were imported into R and some processing performed. The outcome variable classe and user name were converted to factors. Also, the accelerometer data in columns 7 through to 159 were explicitly converted to numeric values.

```{r warning=FALSE}
setwd("~/Dropbox/Coursera/Practical Machine Learning/Course Project")
input<- read.csv(file="pml-training.csv",stringsAsFactors = FALSE)
input$classe<- factor(input$classe)
input$user_name<- factor(input$user_name)
input[,7:159]<- apply(input[,7:159], 2, as.numeric)
```

The input dataset contains `r nrow(input)` rows and `r ncol(input)` columns. 

It was decided to split this input data into training and testing datasets using a 75%/25% split. The first 7 columns were removed as these contain unnecessary information such as row no, user name and various date timestamps. Additionally, it was necessary to remove approx half of the columns due to near zero variance. These were overwhelmingly populated with NA values. 

```{r warning=FALSE}
library(caret)
inTrain<- createDataPartition(y=input$classe, p=0.75, list=FALSE)
training<- input[inTrain,colSums(is.na(input))==0]
testing<- input[-inTrain,colSums(is.na(input))==0]
training<- training[,-c(1:7)]
testing<- testing[,-c(1:7)]
```

The training and test datasets both have `r ncol(training)` columns and `r nrow(training)` and `r nrow(testing)` rows respectively. As a final check the near zero variance check was run again confirming each remaining column had sufficient uniqueness.

```{r warning=FALSE}
nzv<- nearZeroVar(training,saveMetrics = TRUE)
head(nzv)
```

#### Initial analysis
Some initial analysis was done on the training dataset. Indications were that there were an approximately even spread of 5 output classes and that the accelerometer data tended to cluster around particular values.

```{r warning=FALSE}
table(training$classe)
pairs(training[,c(1:5)])
```

Given the categorical nature of outcome 'classe', it was determined to build a decision tree using caret package.

```{r warning=FALSE}
set.seed(123)
modFit1<- train(classe~.,method="rpart",data=training)
modFit1
modFit1$finalModel
```

With the default parameters in caret, it can be seen that the final model was created by bootstrapping with 25 samples. This cross validation ensures that parameters can be tuned and the testing dataset alone can be used to independently determine accuracy. 

```{r warning=FALSE}
confusionMatrix(predict(modFit1,testing),testing$classe)
```

The accuracy of the testing dataset is ~48% which is a lot poorer than expected. 